# api_routes.py
import logging
import os
import json
import gzip 
import asyncio
# --- –£–î–ê–õ–ï–ù–û: time, aiohttp, defaultdict ---
from fastapi import APIRouter, HTTPException, Depends, Security, Response
from fastapi.responses import JSONResponse
from fastapi.security import HTTPBearer
from pydantic import BaseModel 
from typing import List, Dict, Any, Optional

# --- –ò–º–ø–æ—Ä—Ç—ã Redis ---
from redis.asyncio import Redis as AsyncRedis
# ---------------------

# --- –ò–º–ø–æ—Ä—Ç—ã –º–æ–¥—É–ª–µ–π –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è ---
from cache_manager import (
    get_redis_connection,
    load_raw_bytes_from_cache,
    load_from_cache,
    save_to_cache,
)
# --- –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã –£–î–ê–õ–ï–ù–´ —Å –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è ---
# (–û–Ω–∏ –±—É–¥—É—Ç –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–π, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å Cyclic Import)
# from data_collector import fetch_market_data
# from data_collector.aggregation_target import run_target_generation_process as run_target_generation_process_func
from data_collector.coin_source import get_coins as get_all_symbols
# from data_collector.direct_fetcher import run_direct_data_collection
# -----------------------------------------------------------------------


# --- –ò–º–ø–æ—Ä—Ç—ã –∏–∑ config ---
from config import (
    ALLOWED_CACHE_KEYS,
    SECRET_TOKEN,
    ACTIVE_TIMEFRAME_PAIR,
    # --- –£–î–ê–õ–ï–ù–û: CONCURRENCY_LIMIT ---
)


# –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç Router
router = APIRouter()
security = HTTPBearer()

# --- –ö–û–î –ò–ó "–ü–†–û–ï–ö–¢–ê –ê" (–î–õ–Ø .../direct) ---
class MarketDataRequest(BaseModel):
    timeframes: List[str]
    symbols: Optional[List[str]] = None

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π semaphore –¥–ª—è –∑–∞—â–∏—Ç—ã /direct
DIRECT_ENDPOINT_SEMAPHORE = asyncio.Semaphore(1)
# ----------------------------------------


def _get_active_timeframes() -> tuple[str, str]:
    """
    –ü–∞—Ä—Å–∏—Ç ACTIVE_TIMEFRAME_PAIR –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞.
    """
    try:
        base_tf, target_tf = ACTIVE_TIMEFRAME_PAIR.split('_')
        return base_tf.lower(), target_tf.lower()
    except ValueError:
        logging.critical(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ACTIVE_TIMEFRAME_PAIR: {ACTIVE_TIMEFRAME_PAIR}. –û–∂–∏–¥–∞–µ—Ç—Å—è 'BASE_TARGET'.")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤.")


async def verify_cron_secret(credentials: HTTPBearer = Security(security)):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–µ–∫—Ä–µ—Ç–Ω—ã–π —Ç–æ–∫–µ–Ω –¥–ª—è Cron-Job."""
    if not SECRET_TOKEN:
        logging.error("[CRON_JOB_API] –ó–∞–ø—Ä–æ—Å –æ—Ç–∫–ª–æ–Ω–µ–Ω: SECRET_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ (503).")
        raise HTTPException(
            status_code=503,
            detail="–°–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –°–µ–∫—Ä–µ—Ç –¥–ª—è Cron-Job –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω."
        )
    
    if credentials.credentials != SECRET_TOKEN:
        logging.warning("[CRON_JOB_API] –ó–∞–ø—Ä–æ—Å –æ—Ç–∫–ª–æ–Ω–µ–Ω: –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–æ–∫–µ–Ω (403).")
        raise HTTPException(
            status_code=403,
            detail="–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω: –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–æ–∫–µ–Ω."
        )
    return True


async def _run_data_collection_task(timeframe: str, log_prefix: str):
    """
    –û–±—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ —Å–±–æ—Ä–∞ Klines/OI/FR (–¥–ª—è Base-TF).
    (–ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —É–¥–∞–ª–µ–Ω–∞)
    """
    # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï: "–õ–µ–Ω–∏–≤—ã–π" –∏–º–ø–æ—Ä—Ç ---
    from data_collector import fetch_market_data
    # ---------------------------------
    
    redis_conn = await get_redis_connection()
    if not redis_conn:
        raise HTTPException(status_code=503, detail="–°–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: Redis –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω.")

    try:
        # 1. –°–±–æ—Ä –º–æ–Ω–µ—Ç
        all_coins = await get_all_symbols()
        if not all_coins:
            raise HTTPException(status_code=503, detail="–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–Ω–µ—Ç.")
         
        # 2. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ 
        logging.info(f"{log_prefix} –ó–∞–ø—É—Å–∫ fetch_market_data ({timeframe}, {len(all_coins)} –º–æ–Ω–µ—Ç)...")
        # (–í—ã–∑—ã–≤–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π fetch_market_data, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–±–µ—Ä–µ—Ç Klines, OI –∏ FR)
        klines_data = await fetch_market_data(all_coins, timeframe, prefetched_fr_data=None)
        
        if not klines_data or not klines_data.get('data'):
            raise HTTPException(status_code=404, detail=f"–î–∞–Ω–Ω—ã–µ {timeframe} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")

        # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        # (–ò—Å–ø–æ–ª—å–∑—É–µ–º f"cache:{timeframe}", –∞ –Ω–µ key –∏–∑ load_raw_bytes)
        await save_to_cache(redis_conn, f"cache:{timeframe}", klines_data)
        
        logging.info(f"{log_prefix} ‚úÖ –ó–∞–¥–∞—á–∞ {timeframe} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
        return {"status": "ok", "message": f"–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö {timeframe} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω."}

    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"{log_prefix} –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        if redis_conn:
            pass


# === –ù–û–í–´–ô –≠–ù–î–ü–û–ò–ù–¢: –°–ë–û–† –ë–ê–ó–û–í–û–ì–û –¢–ê–ô–ú–§–†–ï–ô–ú–ê (4H –∏–ª–∏ 12H) ===
@router.post("/internal/update-base-data", status_code=200)
async def update_base_data(
    is_authenticated: bool = Depends(verify_cron_secret)
):
    """
    (–°–ò–ù–•–†–û–ù–ù–´–ô) –ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–±–æ—Ä –±–∞–∑–æ–≤–æ–≥–æ TF (4h –∏–ª–∏ 12h) —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ñ–∏–≥—É.
    """
    base_tf, _ = _get_active_timeframes()
    log_prefix = f"[API_BASE_SYNC:{base_tf.upper()}]"
    
    return await _run_data_collection_task(base_tf, log_prefix)


# === –ù–û–í–´–ô –≠–ù–î–ü–û–ò–ù–¢: –ì–ï–ù–ï–†–ê–¶–ò–Ø –¶–ï–õ–ï–í–û–ì–û –¢–ê–ô–ú–§–†–ï–ô–ú–ê (8H –∏–ª–∏ 1D) ===
@router.post("/internal/generate-target", status_code=200)
async def generate_target_data(
    is_authenticated: bool = Depends(verify_cron_secret)
):
    """
    (–°–ò–ù–•–†–û–ù–ù–´–ô) –ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–≥—Ä–µ–≥–∞—Ü–∏—é —Ü–µ–ª–µ–≤–æ–≥–æ TF (8h –∏–ª–∏ 1d) —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ñ–∏–≥—É.
    (–í–Ω–µ—à–Ω—è—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —É–¥–∞–ª–µ–Ω–∞)
    """
    # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï: "–õ–µ–Ω–∏–≤—ã–π" –∏–º–ø–æ—Ä—Ç ---
    from data_collector.aggregation_target import run_target_generation_process as run_target_generation_process_func
    # ---------------------------------
    
    base_tf, target_tf = _get_active_timeframes()
    log_prefix = f"[API_TARGET_SYNC:{target_tf.upper()}]"
    
    try:
        # 1. –°–±–æ—Ä –º–æ–Ω–µ—Ç
        all_coins = await get_all_symbols()
        if not all_coins:
            raise HTTPException(status_code=503, detail="–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–Ω–µ—Ç.")
        
        # 3. –ê–≥—Ä–µ–≥–∞—Ü–∏—è
        logging.info(f"{log_prefix} –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ {target_tf} –∏–∑ {base_tf}...")
        
        success = await run_target_generation_process_func(
            target_tf,  
            base_tf,    
            all_coins   
        )
        
        if not success:
             raise HTTPException(status_code=500, detail=f"–ê–≥—Ä–µ–≥–∞—Ü–∏—è {target_tf} –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π.")
        
        logging.info(f"{log_prefix} ‚úÖ –ó–∞–¥–∞—á–∞ {target_tf} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
        return {"status": "ok", "message": f"–ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö {target_tf} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∞."}
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"{log_prefix} –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: {e}")
    


@router.get("/get-cache/{key}")
async def get_raw_cache(key: str):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—ã—Ä—ã–µ —Å–∂–∞—Ç—ã–µ GZIP –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞ Redis."""
    if key not in ALLOWED_CACHE_KEYS:
         raise HTTPException(status_code=400, detail=f"–ö–ª—é—á '{key}' –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω.")

    redis_conn = await get_redis_connection()
    if not redis_conn:
        raise HTTPException(status_code=503, detail="–°–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: Redis –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω.")

    # (–ò—Å–ø–æ–ª—å–∑—É–µ–º f"cache:{key}", –∞ –Ω–µ key –∏–∑ load_raw_bytes)
    data_bytes = await load_raw_bytes_from_cache(f"cache:{key}", redis_conn=redis_conn)
    
    if data_bytes:
        return Response(
            content=data_bytes,
            media_type="application/json",
            headers={
                 "Content-Encoding": "gzip",
                "Content-Type": "application/json; charset=utf-8",
                "Cache-Control": "no-transform"
            }
        )
    else:
        raise HTTPException(status_code=404, detail=f"–ö–ª—é—á '{key}' –ø—É—Å—Ç.")


@router.get("/health")
@router.head("/health")
async def health_check():
    """–ü—Ä–æ—Å—Ç–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∂–∏–≤."""
    return {"status": "ok"}


# === üöÄ –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ù–ï–ó–ê–í–ò–°–ò–ú–´–ô –≠–ù–î–ü–û–ò–ù–¢ (–õ–û–ì–ò–ö–ê –í–´–ù–ï–°–ï–ù–ê) ===
@router.post("/get-market-data/direct")
async def get_market_data_direct(request: MarketDataRequest):
    """
    (–ù–ï–ó–ê–í–ò–°–ò–ú–´–ô) –ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–±–æ—Ä Klines/OI/FR "–≤–∂–∏–≤—É—é", –º–∏–Ω—É—è –∫—ç—à.
    –†–µ–∞–ª–∏–∑—É–µ—Ç –∫–∞—Å—Ç–æ–º–Ω—É—é –ª–æ–≥–∏–∫—É —Å–±–æ—Ä–∞ (1/12/1d = K+OI, 4/8h = K+OI+FR).
    –í–ù–ò–ú–ê–ù–ò–ï: –ó–∞–ø—Ä–æ—Å –º–æ–∂–µ—Ç –∑–∞–Ω–∏–º–∞—Ç—å 60-90+ —Å–µ–∫—É–Ω–¥.
    –ó–∞—â–∏—â–µ–Ω –æ—Ç DDoS: –º–∞–∫—Å–∏–º—É–º 1 –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å.
    """
    # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï: "–õ–µ–Ω–∏–≤—ã–π" –∏–º–ø–æ—Ä—Ç ---
    from data_collector.direct_fetcher import run_direct_data_collection
    # ---------------------------------
    
    if not request.timeframes:
        raise HTTPException(status_code=400, detail="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å timeframe.")
    
    if len(request.timeframes) > 1:
        raise HTTPException(status_code=400, detail="–¢–æ–ª—å–∫–æ –æ–¥–∏–Ω timeframe –∑–∞ –∑–∞–ø—Ä–æ—Å.")
    
    timeframe = request.timeframes[0]
    
    if timeframe not in ALLOWED_CACHE_KEYS:
        raise HTTPException(status_code=400, detail=f"Timeframe '{timeframe}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.")

    # ‚úÖ –ó–∞—â–∏—Ç–∞ –æ—Ç DDoS
    async with DIRECT_ENDPOINT_SEMAPHORE:
        log_prefix = f"[API_DIRECT:{timeframe.upper()}]"
        logging.info(f"{log_prefix} –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å. –°–µ–º–∞—Ñ–æ—Ä –∑–∞—Ö–≤–∞—á–µ–Ω.")
        
        try:
            # 1. –í—ã–∑—ã–≤–∞–µ–º –Ω–æ–≤—É—é –Ω–µ–∑–∞–≤–∏—Å–∏–º—É—é —Ñ—É–Ω–∫—Ü–∏—é
            # –û–Ω–∞ —Å–∞–º–∞ –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç —Å–±–æ—Ä, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é, –ø–∞—Ä—Å–∏–Ω–≥, —Å–ª–∏—è–Ω–∏–µ –∏ GZIP
            return await run_direct_data_collection(timeframe, request.symbols)

        except HTTPException as e:
            # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º HTTP –æ—à–∏–±–∫–∏ (404, 503, 500) –∏–∑ direct_fetcher
            raise e
        # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: IndentationError ---
        # (–≠—Ç–æ—Ç –±–ª–æ–∫ —Å–¥–≤–∏–Ω—É—Ç –≤–ª–µ–≤–æ, —á—Ç–æ–±—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å `try`)
        except Exception as e:
             # –õ–æ–≤–∏–º –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ (–Ω–µ-HTTP) –æ—à–∏–±–∫–∏
             logging.error(f"{log_prefix} –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê (API_ROUTES): {e}", exc_info=True)
             raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: {e}")
# === üöÄ –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–Ø ===